OK, well I got seriously sidetracked by the damned authentication process of GS,
There is no access to product page un-authenticated!
they wont allow the normal python authentication methods (like urllib auth)
copying the cookies didn't work
the only thing the lets you load the page is litterally copying over the header of the http request from the browser to a text file and then using this to override python's "requests" headers.
Using any kind of unrecognized POST requests will get you blocked, so login could be difficult

So this is what we'll have to do:

It probably needs to come from the same IP address, ie, your firefox browser needs the same IP address as the scrapper, so yes, use a proxy!

Open firefox, login to GS and go to a product page.
open the firefox console by pressing Ctrl+Shift+K
Go to network and reload the page.
scroll back up again and find the first get request, click it to open the sidebar, and inside there locate headers and click raw headers.

Copy the request headers to ./tmp/ff_headers.txt

=================================================

OK, well the search results (catalog) page doesn't contain relevant data
IE http://www.globalspec.com/search/products?page=ms#sqid=19041002&comp=2940&show=products

It instead populates this with the contents of a json request to 

http://www.globalspec.com/Search/GetProductResults?sqid=19041002&comp=2940&show=products&origWebHitId=471275866&method=getNewResults

The keys are:
sqid - Get this from the sqid of the first url
comp - Get this again from the original request name
WebHitId - this is in the page's <span id="webhit">

So we need to take the original url, extract the sqid and comp arguments
fetch the page, extract WebHitId, and generate a request to the json url.

Then we need to harvest that for more catalogs or products (it contains both)
